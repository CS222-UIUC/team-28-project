{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==any\n",
      "  Downloading https://huggingface.co/spacy/en_core_web_sm/resolve/main/en_core_web_sm-any-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m917.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/anaconda3/lib/python3.11/site-packages (from en-core-web-sm==any) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (2.7.4)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/anaconda3/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==any) (0.1.0)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install https://huggingface.co/spacy/en_core_web_sm/resolve/main/en_core_web_sm-any-py3-none-any.whl\n",
    "#or use rtf for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: remind me to go to the church for CS225 today at 10am with Ashley\n",
      "Extracted Entities: {'task': None, 'participants': ['Ashley'], 'date': '2025-03-02', 'time': '10:00', 'priority': 'normal', 'locations': ['the church'], 'description': 'remind me to go to the church for CS225 today at 10am with Ashley'}\n",
      "\n",
      "Input: Schedule a meeting at the downtown office with John next Tuesday\n",
      "Extracted Entities: {'task': 'meeting', 'participants': ['John'], 'date': None, 'time': None, 'priority': 'normal', 'locations': ['the downtown office'], 'description': 'Schedule a meeting at the downtown office with John next Tuesday'}\n",
      "\n",
      "Input: Me and Jane need to go to UIUC test tomorrow.\n",
      "Extracted Entities: {'task': None, 'participants': ['Jane'], 'date': '2025-03-03', 'time': None, 'priority': 'normal', 'locations': ['UIUC', 'UIUC test'], 'description': 'Me and Jane need to go to UIUC test tomorrow.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import spacy\n",
    "from dateparser import parse as date_parse\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_entities(text):\n",
    "    \"\"\"\n",
    "    Parse the user text using spaCy and extract:\n",
    "    - Participants (PERSON entities)\n",
    "    - Date and Time (DATE, TIME entities) via spaCy + dateparser\n",
    "    - Task type (using a simple rule-based approach)\n",
    "    - Priority (using a simple rule-based approach)\n",
    "    - Locations: from spaCy (if labeled as FAC, GPE, LOC, or ORG)\n",
    "      and from rule-based detection if the words \"at\" or \"to\" are followed by a noun phrase,\n",
    "      with special checks for \"to\" (to avoid catching infinitive markers).\n",
    "    - Description (fallback to the original text)\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Prepare a dictionary to hold extracted info\n",
    "    extracted = {\n",
    "        \"task\": None,\n",
    "        \"participants\": [],\n",
    "        \"date\": None,\n",
    "        \"time\": None,\n",
    "        \"priority\": None,\n",
    "        \"locations\": [],\n",
    "        \"description\": None\n",
    "    }\n",
    "\n",
    "    # Define location labels from spaCy\n",
    "    location_labels = {\"FAC\", \"GPE\", \"LOC\", \"ORG\"}\n",
    "\n",
    "    # Identify named entities from spaCy\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            extracted[\"participants\"].append(ent.text)\n",
    "        elif ent.label_ == \"DATE\":\n",
    "            dt = date_parse(ent.text)\n",
    "            if dt:\n",
    "                extracted[\"date\"] = dt.strftime(\"%Y-%m-%d\")\n",
    "        elif ent.label_ == \"TIME\":\n",
    "            dt = date_parse(ent.text)\n",
    "            if dt:\n",
    "                extracted[\"time\"] = dt.strftime(\"%H:%M\")\n",
    "        elif ent.label_ in location_labels:\n",
    "            extracted[\"locations\"].append(ent.text)\n",
    "\n",
    "    # Simple rule-based approach for task and priority\n",
    "    task_keywords = [\"meeting\", \"call\", \"email\", \"reminder\", \"schedule\"]\n",
    "    priority_keywords = [\"urgent\", \"high-priority\", \"low-priority\"]\n",
    "\n",
    "    for token in doc:\n",
    "        # Check if token matches any known task keywords\n",
    "        if token.lemma_.lower() in task_keywords:\n",
    "            extracted[\"task\"] = token.lemma_.lower()\n",
    "        # Check for priority keywords\n",
    "        if token.lemma_.lower() in priority_keywords:\n",
    "            extracted[\"priority\"] = token.lemma_.lower()\n",
    "\n",
    "    # Set a default priority if none was found\n",
    "    if not extracted[\"priority\"]:\n",
    "        extracted[\"priority\"] = \"normal\"\n",
    "\n",
    "    # Rule-based detection for locations after \"at\" or \"to\"\n",
    "    for token in doc:\n",
    "        if token.text.lower() in {\"at\", \"to\"} and token.i < len(doc) - 1:\n",
    "            # For \"to\", skip if the following token is a verb (likely an infinitive marker)\n",
    "            if token.text.lower() == \"to\" and doc[token.i+1].pos_ == \"VERB\":\n",
    "                continue\n",
    "            # Also skip if the immediate next token is labeled as TIME\n",
    "            if doc[token.i+1].ent_type_ == \"TIME\":\n",
    "                continue\n",
    "\n",
    "            candidate = None\n",
    "            # Attempt to get the following noun chunk as the location\n",
    "            for chunk in doc.noun_chunks:\n",
    "                if chunk.start == token.i + 1:\n",
    "                    candidate = chunk.text\n",
    "                    break\n",
    "            # If no noun chunk was found, just use the immediate token.\n",
    "            if not candidate:\n",
    "                candidate = doc[token.i+1].text\n",
    "\n",
    "            if candidate not in extracted[\"locations\"]:\n",
    "                extracted[\"locations\"].append(candidate)\n",
    "\n",
    "    # For the description, store the entire original text\n",
    "    extracted[\"description\"] = text\n",
    "\n",
    "    return extracted\n",
    "\n",
    "# Main testing code\n",
    "if __name__ == \"__main__\":\n",
    "    # Some example inputs to test\n",
    "    test_sentences = [\n",
    "        \"remind me to go to the church for CS225 today at 10am with Ashley\",\n",
    "        \"Schedule a meeting at the downtown office with John next Tuesday\",\n",
    "        \"Me and Jane need to go to UIUC test tomorrow.\"\n",
    "    ]\n",
    "\n",
    "    for sentence in test_sentences:\n",
    "        result = extract_entities(sentence)\n",
    "        print(f\"\\nInput: {sentence}\")\n",
    "        print(\"Extracted Entities:\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
